{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3c33ea9-b55f-415a-9eef-0108a30cdf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from unet import UNet\n",
    "from torch.utils.data import DataLoader\n",
    "from skimage.transform import resize\n",
    "from dataset import *\n",
    "from transformations import *\n",
    "from model import *\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb525800-d1f8-46eb-8f91-7c619ebded6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loader: 100\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_file_path, mask_file_path):\n",
    "        self.images = np.load(image_file_path)\n",
    "        self.masks = np.load(mask_file_path)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Get an individual image and mask pair from the dataset\n",
    "        image = self.images[index]\n",
    "        mask = self.masks[index]\n",
    "\n",
    "        # Convert the image and mask to PyTorch tensors\n",
    "        image = torch.from_numpy(image)\n",
    "        mask = torch.from_numpy(mask)\n",
    "\n",
    "        # Return the processed image and mask\n",
    "        return image, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "# ################################################ train data\n",
    "# # Paths to your image and mask .npy files\n",
    "# image_file_path_tr = r'/content/drive/MyDrive/data/Train_img_10frame_256.npy'\n",
    "# mask_file_path_tr = r'/content/drive/MyDrive/data/Train_msk_10frame_256.npy'\n",
    "\n",
    "\n",
    "# batch_size = 5\n",
    "# val_split = 0.2\n",
    "\n",
    "# # Create an instance of your custom dataset\n",
    "# dataset = CustomDataset(image_file_path_tr, mask_file_path_tr)\n",
    "\n",
    "# dataset_size = len(dataset)\n",
    "# val_size = int(val_split * dataset_size)\n",
    "# train_size = dataset_size - val_size\n",
    "# print(dataset_size, val_size, train_size)\n",
    "# train_set, val_set = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# # Create a DataLoader\n",
    "# train_dataloader = DataLoader(train_set, batch_size=batch_size , shuffle=True, num_workers=0)\n",
    "# val_dataloader = DataLoader(val_set, batch_size=batch_size , shuffle=True, num_workers=0)\n",
    "# ################################################ validation data\n",
    "# Paths to your image and mask .npy files\n",
    "image_file_path_val = 'Test_img_10frame_256.npy'\n",
    "mask_file_path_val = 'Test_msk_10frame_256.npy'\n",
    "\n",
    "\n",
    "# Create an instance of your custom dataset\n",
    "dataset = CustomDataset(image_file_path_val, mask_file_path_val)\n",
    "\n",
    "# Create a DataLoader\n",
    "test_dataloader = DataLoader(dataset, batch_size=1, shuffle=True, num_workers=0)\n",
    "\n",
    "\n",
    "print(\"test_loader:\", len(dataset))\n",
    "\n",
    "\n",
    "# Iterate over the dataloader to access batches of image and mask pairs\n",
    "# for batch in test_dataloader:\n",
    "#     # Unpack the batch into images and masks\n",
    "#     images, masks = batch\n",
    "#     print(images.shape)\n",
    "#     print(masks.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba7bab20-f142-451a-995e-325fca6e1bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  # Use GPU if available\n",
    "# device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e709adae-0c93-40e1-b52c-0901e6b31c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "3D U-Net: Learning Dense Volumetric Segmentation from Sparse Annotation\n",
    "Paper URL: https://arxiv.org/abs/1606.06650\n",
    "Author: Amir Aghdam\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from torch import nn\n",
    "# from torchsummary import summary\n",
    "import torch\n",
    "import time\n",
    "\n",
    "class Conv3DBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    The basic block for double 3x3x3 convolutions in the analysis path\n",
    "    -- __init__()\n",
    "    :param in_channels -> number of input channels\n",
    "    :param out_channels -> desired number of output channels\n",
    "    :param bottleneck -> specifies the bottlneck block\n",
    "    -- forward()\n",
    "    :param input -> input Tensor to be convolved\n",
    "    :return -> Tensor\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bottleneck = False) -> None:\n",
    "        super(Conv3DBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(in_channels= in_channels, out_channels=out_channels//2, kernel_size=(3,3,3), padding=1)\n",
    "        self.bn1 = nn.BatchNorm3d(num_features=out_channels//2)\n",
    "        self.conv2 = nn.Conv3d(in_channels= out_channels//2, out_channels=out_channels, kernel_size=(3,3,3), padding=1)\n",
    "        self.bn2 = nn.BatchNorm3d(num_features=out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.bottleneck = bottleneck\n",
    "        if not bottleneck:\n",
    "            self.pooling = nn.MaxPool3d(kernel_size=(2,2,2), stride=2)\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        res = self.relu(self.bn1(self.conv1(input)))\n",
    "        res = self.relu(self.bn2(self.conv2(res)))\n",
    "        out = None\n",
    "        if not self.bottleneck:\n",
    "            out = self.pooling(res)\n",
    "        else:\n",
    "            out = res\n",
    "        return out, res\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class UpConv3DBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    The basic block for upsampling followed by double 3x3x3 convolutions in the synthesis path\n",
    "    -- __init__()\n",
    "    :param in_channels -> number of input channels\n",
    "    :param out_channels -> number of residual connections' channels to be concatenated\n",
    "    :param last_layer -> specifies the last output layer\n",
    "    :param num_classes -> specifies the number of output channels for dispirate classes\n",
    "    -- forward()\n",
    "    :param input -> input Tensor\n",
    "    :param residual -> residual connection to be concatenated with input\n",
    "    :return -> Tensor\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, res_channels=0, last_layer=False, num_classes=None) -> None:\n",
    "        super(UpConv3DBlock, self).__init__()\n",
    "        assert (last_layer==False and num_classes==None) or (last_layer==True and num_classes!=None), 'Invalid arguments'\n",
    "        self.upconv1 = nn.ConvTranspose3d(in_channels=in_channels, out_channels=in_channels, kernel_size=(2, 2, 2), stride=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.bn = nn.BatchNorm3d(num_features=in_channels//2)\n",
    "        self.conv1 = nn.Conv3d(in_channels=in_channels+res_channels, out_channels=in_channels//2, kernel_size=(3,3,3), padding=(1,1,1))\n",
    "        self.conv2 = nn.Conv3d(in_channels=in_channels//2, out_channels=in_channels//2, kernel_size=(3,3,3), padding=(1,1,1))\n",
    "        self.last_layer = last_layer\n",
    "        if last_layer:\n",
    "            self.conv3 = nn.Conv3d(in_channels=in_channels//2, out_channels=num_classes, kernel_size=(1,1,1))\n",
    "\n",
    "\n",
    "    def forward(self, input, residual=None):\n",
    "        out = self.upconv1(input)\n",
    "        if residual!=None:\n",
    "          # print(\"shape input after upconv1:\", out.shape)\n",
    "          # print(\"shape residual:\", residual.shape)\n",
    "          if(out.shape[2]==4):\n",
    "              # print(\"flag\")\n",
    "              out = F.interpolate(out, size=(5, 128, 128), mode='trilinear', align_corners=False)\n",
    "          out = torch.cat((out, residual), 1)\n",
    "          # print(\"--------- output of upblock:\")\n",
    "          # print(\"concate shape:\", out.shape)\n",
    "          # print(\"Flag none\")\n",
    "        out = self.relu(self.bn(self.conv1(out)))\n",
    "        # print(\"out shape:\", out.shape)\n",
    "        out = self.relu(self.bn(self.conv2(out)))\n",
    "        # print(\"out shape:\", out.shape)\n",
    "        if self.last_layer: out = self.conv3(out)\n",
    "        # print(\"out shape:\", out.shape)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class UNet3D(nn.Module):\n",
    "    \"\"\"\n",
    "    The 3D UNet model\n",
    "            the source code of 3D U-Net\n",
    "            https://github.com/AghdamAmir/3D-UNet/blob/main/train.py\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, num_classes, level_channels=[64, 128, 256], bottleneck_channel=512) -> None:\n",
    "        super(UNet3D, self).__init__()\n",
    "        level_1_chnls, level_2_chnls, level_3_chnls = level_channels[0], level_channels[1], level_channels[2]\n",
    "        self.a_block1 = Conv3DBlock(in_channels=in_channels, out_channels=level_1_chnls)\n",
    "        self.a_block2 = Conv3DBlock(in_channels=level_1_chnls, out_channels=level_2_chnls)\n",
    "        self.a_block3 = Conv3DBlock(in_channels=level_2_chnls, out_channels=level_3_chnls)\n",
    "        self.bottleNeck = Conv3DBlock(in_channels=level_3_chnls, out_channels=bottleneck_channel, bottleneck= True)\n",
    "        self.s_block3 = UpConv3DBlock(in_channels=bottleneck_channel, res_channels=level_3_chnls)\n",
    "        self.s_block2 = UpConv3DBlock(in_channels=level_3_chnls, res_channels=level_2_chnls)\n",
    "        self.s_block1 = UpConv3DBlock(in_channels=level_2_chnls, res_channels=level_1_chnls, num_classes=num_classes, last_layer=True)\n",
    "\n",
    "    def forward(self, input):\n",
    "        #Analysis path forward feed\n",
    "        # print(\"shape of input: \", input.shape)\n",
    "        out, residual_level1 = self.a_block1(input)\n",
    "        # print(\"shape of out:\", out.shape)\n",
    "        # print(\"shape of residual_level1: \", residual_level1.shape)\n",
    "\n",
    "        out, residual_level2 = self.a_block2(out)\n",
    "        # print(\"shape of out:\", out.shape)\n",
    "        # print(\"shape of residual_level2: \", residual_level2.shape)\n",
    "\n",
    "        out, residual_level3 = self.a_block3(out)\n",
    "        # print(\"shape of out:\", out.shape)\n",
    "        # print(\"shape of residual_level3: \", residual_level3.shape)\n",
    "\n",
    "        out, _ = self.bottleNeck(out)\n",
    "        # print(\"shape of out bottleNeck: \", out.shape)\n",
    "\n",
    "        #Synthesis path forward feed\n",
    "        out = self.s_block3(out, residual_level3)\n",
    "        # print(\"shape s_block3: \", out.shape)\n",
    "        out = self.s_block2(out, residual_level2)\n",
    "        # print(\"shape s_block2: \", out.shape)\n",
    "        out = self.s_block1(out, residual_level1)\n",
    "        # print(\"shape s_block3: \", out.shape)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59b455f9-cb19-4b71-9eda-1e7510386be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e2c86e6-4c85-4e8c-9446-8072d43e68d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jul  4 15:04:10 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.108.03   Driver Version: 510.108.03   CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A10          On   | 00000000:17:00.0 Off |                    0 |\n",
      "|  0%   55C    P8    23W / 150W |      2MiB / 23028MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A10          On   | 00000000:CA:00.0 Off |                    0 |\n",
      "|  0%   63C    P0    87W / 150W |  19629MiB / 23028MiB |     28%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "52263818-6a5f-4d37-b955-4521e76dc322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = UNet3D(num_classes=4, in_channels=1).to(device)\n",
    "model.load_state_dict(torch.load('final_model-4.pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7bf73f93-dd81-4713-8771-bc4e7b023274",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import monai\n",
    "\n",
    "def one_hot_encoders(input_tensor, num_classes=4):\n",
    "    tensor_list = []\n",
    "    for i in range(num_classes):\n",
    "        temp_prob = input_tensor == i * torch.ones_like(input_tensor)\n",
    "        tensor_list.append(temp_prob)\n",
    "    output_tensor = torch.cat(tensor_list, dim=1)\n",
    "    return output_tensor.float()\n",
    "\n",
    "def compute_metrics(test_dataloader, model, device, num_classes=4):\n",
    "    img, msks = next(iter(test_dataloader))\n",
    "    \n",
    "    outputs = np.empty((len(test_dataloader), num_classes, img.size(dim=1), img.size(dim=2), img.size(dim=3)))\n",
    "    labels = np.empty((len(test_dataloader), num_classes, img.size(dim=1), img.size(dim=2), img.size(dim=3)))\n",
    "    i = 0\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for input, label in test_dataloader:\n",
    "            input = input.to(device)\n",
    "            label = label.to(device)\n",
    "            input = input.unsqueeze(1)\n",
    "\n",
    "            output = model(input)\n",
    "            outputs_soft = torch.softmax(output, dim=1)\n",
    "            label = one_hot_encoders(label.unsqueeze(1), num_classes=4)\n",
    "\n",
    "            outputs[i,:,:,:,:] = outputs_soft[0].cpu()\n",
    "            labels[i,:,:,:,:] = label[0].cpu()\n",
    "            i += 1\n",
    "            \n",
    "    outputs = torch.from_numpy(outputs)\n",
    "    labels = torch.from_numpy(labels)\n",
    "    \n",
    "    dice = monai.metrics.compute_dice(outputs, labels, include_background=False)\n",
    "    hausdorff = monai.metrics.compute_hausdorff_distance(outputs, labels)\n",
    "    print('çlasswise dice')\n",
    "    # print(dice)\n",
    "    mean_dice = torch.mean(dice, dim=0)\n",
    "    cls_dice = torch.mean(dice, dim=1)\n",
    "    print('Dice score')\n",
    "    print(f'\\n Mean Dice score: {torch.mean(mean_dice):.4f}')\n",
    "    print(dice)\n",
    "    \n",
    "    mean_hausdorff = torch.mean(hausdorff, dim=0)\n",
    "    print('Hausdorff distance')\n",
    "    print(f'\\n Mean Hausdorff disctance: {torch.mean(mean_hausdorff):.4f}')\n",
    "    print(hausdorff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ada330bb-e883-4e6b-a20f-17b43aee5e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 256, 256])\n",
      "torch.Size([1, 10, 256, 256])\n",
      "torch.Size([1, 4, 10, 256, 256])\n",
      "torch.Size([1, 4, 10, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "for inp, label in test_dataloader:\n",
    "    print(inp.shape)\n",
    "    print(label.shape)\n",
    "    label = one_hot_encoders(label.unsqueeze(1), num_classes=4)\n",
    "    print(label.shape)\n",
    "    inp = inp.to(device)\n",
    "    label = label.to(device)\n",
    "    inp = inp.unsqueeze(1)\n",
    "    output = model(inp)\n",
    "    print(output.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ebaef202-1bf9-4f73-bd8a-f3e7796d5203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "çlasswise dice\n",
      "Dice score\n",
      "\n",
      " Mean Dice score: 0.3875\n",
      "tensor([[0.4078, 0.4634, 0.5253],\n",
      "        [0.5491, 0.3463, 0.6434],\n",
      "        [0.2045, 0.0789, 0.1948],\n",
      "        [0.4183, 0.4967, 0.6193],\n",
      "        [0.4986, 0.4650, 0.7187],\n",
      "        [0.0254, 0.2439, 0.1381],\n",
      "        [0.2787, 0.4209, 0.2110],\n",
      "        [0.3685, 0.3964, 0.2685],\n",
      "        [0.1523, 0.3506, 0.3327],\n",
      "        [0.4610, 0.4101, 0.5030],\n",
      "        [0.0237, 0.0266, 0.0059],\n",
      "        [0.2859, 0.3974, 0.4686],\n",
      "        [0.2476, 0.2820, 0.3501],\n",
      "        [0.1501, 0.2328, 0.4158],\n",
      "        [0.4695, 0.3079, 0.6291],\n",
      "        [0.6399, 0.2532, 0.6664],\n",
      "        [0.4009, 0.3860, 0.2370],\n",
      "        [0.6183, 0.4174, 0.7399],\n",
      "        [0.6841, 0.3425, 0.5220],\n",
      "        [0.3700, 0.4498, 0.3325],\n",
      "        [0.3878, 0.4818, 0.7123],\n",
      "        [0.5443, 0.4136, 0.6955],\n",
      "        [0.4966, 0.3688, 0.3226],\n",
      "        [0.0873, 0.2505, 0.3445],\n",
      "        [0.1641, 0.2448, 0.1609],\n",
      "        [0.5534, 0.2777, 0.6434],\n",
      "        [0.1331, 0.3288, 0.1871],\n",
      "        [0.1952, 0.1563, 0.3789],\n",
      "        [0.4474, 0.3155, 0.3712],\n",
      "        [0.3126, 0.3774, 0.4247],\n",
      "        [0.5222, 0.3367, 0.5727],\n",
      "        [0.5622, 0.3596, 0.6452],\n",
      "        [0.4628, 0.3359, 0.4087],\n",
      "        [0.4272, 0.3575, 0.5328],\n",
      "        [0.2818, 0.3754, 0.5610],\n",
      "        [0.2065, 0.3521, 0.1228],\n",
      "        [0.3031, 0.2723, 0.4875],\n",
      "        [0.1900, 0.2594, 0.1538],\n",
      "        [0.4618, 0.2704, 0.6054],\n",
      "        [0.2117, 0.4100, 0.2865],\n",
      "        [0.3458, 0.2922, 0.6341],\n",
      "        [0.5282, 0.3454, 0.6032],\n",
      "        [0.0753, 0.3777, 0.1389],\n",
      "        [0.4477, 0.3421, 0.6192],\n",
      "        [0.1256, 0.4084, 0.5197],\n",
      "        [0.2791, 0.1587, 0.3155],\n",
      "        [0.4026, 0.2103, 0.5841],\n",
      "        [0.5290, 0.4222, 0.5959],\n",
      "        [0.2235, 0.3067, 0.4963],\n",
      "        [0.5882, 0.4326, 0.6803],\n",
      "        [0.6030, 0.2521, 0.4760],\n",
      "        [0.3348, 0.3811, 0.1898],\n",
      "        [0.4888, 0.3602, 0.6146],\n",
      "        [0.5375, 0.3141, 0.6221],\n",
      "        [0.1880, 0.4280, 0.6658],\n",
      "        [0.4571, 0.2988, 0.5847],\n",
      "        [0.5288, 0.2502, 0.6186],\n",
      "        [0.5558, 0.3410, 0.5806],\n",
      "        [0.4508, 0.3383, 0.4324],\n",
      "        [0.6266, 0.3037, 0.3282],\n",
      "        [0.0203, 0.4400, 0.5546],\n",
      "        [0.4208, 0.4114, 0.3904],\n",
      "        [0.4631, 0.3057, 0.5683],\n",
      "        [0.4901, 0.3630, 0.5535],\n",
      "        [0.2674, 0.4676, 0.3418],\n",
      "        [0.1507, 0.3742, 0.1824],\n",
      "        [0.5515, 0.5266, 0.6209],\n",
      "        [0.3582, 0.3978, 0.5019],\n",
      "        [0.5005, 0.3761, 0.5031],\n",
      "        [0.2183, 0.1866, 0.3033],\n",
      "        [0.3764, 0.2176, 0.5357],\n",
      "        [0.2946, 0.1986, 0.5969],\n",
      "        [0.3207, 0.2673, 0.5133],\n",
      "        [0.0569, 0.0544, 0.1081],\n",
      "        [0.1103, 0.2981, 0.1976],\n",
      "        [0.6265, 0.3845, 0.6817],\n",
      "        [0.2650, 0.2297, 0.2002],\n",
      "        [0.4141, 0.4433, 0.5682],\n",
      "        [0.2407, 0.2871, 0.2853],\n",
      "        [0.4251, 0.3052, 0.6525],\n",
      "        [0.2961, 0.3658, 0.5532],\n",
      "        [0.2697, 0.1868, 0.5428],\n",
      "        [0.5473, 0.3048, 0.6627],\n",
      "        [0.1550, 0.3833, 0.2746],\n",
      "        [0.3354, 0.2092, 0.3603],\n",
      "        [0.4581, 0.4702, 0.5494],\n",
      "        [0.3364, 0.2914, 0.3977],\n",
      "        [0.5987, 0.4012, 0.7204],\n",
      "        [0.4052, 0.2631, 0.6148],\n",
      "        [0.1665, 0.2800, 0.4274],\n",
      "        [0.3880, 0.4977, 0.2633],\n",
      "        [0.2195, 0.2647, 0.5413],\n",
      "        [0.6486, 0.4455, 0.7756],\n",
      "        [0.1953, 0.3255, 0.4022],\n",
      "        [0.4408, 0.4546, 0.4254],\n",
      "        [0.3381, 0.2662, 0.5906],\n",
      "        [0.2764, 0.2679, 0.3109],\n",
      "        [0.5641, 0.4124, 0.5362],\n",
      "        [0.1562, 0.3095, 0.5305],\n",
      "        [0.6687, 0.4161, 0.6746]])\n",
      "Hausdorff distance\n",
      "\n",
      " Mean Hausdorff disctance: inf\n",
      "tensor([[    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,  9.4340],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf, 23.1733],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf, 26.0960],\n",
      "        [    inf,     inf, 28.7054],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf, 32.2025],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf, 24.8193],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf, 22.3830],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf, 17.7200],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf],\n",
      "        [    inf,     inf,     inf]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "compute_metrics(test_dataloader, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8c8982-205e-427c-acf8-fc9aeedb9b20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
